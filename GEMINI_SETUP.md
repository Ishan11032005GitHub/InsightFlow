# ğŸ¤– Google Gemini AI Integration Guide

## âœ… Setup Complete!

Your InsightFlow backend has been integrated with **Google Gemini Flash Latest** model.

---

## ğŸ“‹ What Was Done

### 1. **Package Installation**
- âœ… Installed `@google/generative-ai` package
- âœ… Package is ready in `Backend/package.json`

### 2. **Configuration Files**
- âœ… Created `.env` file with Gemini settings
- âœ… Environment variables configured

### 3. **AI Integration**
- âœ… Updated `utils/aiMock.js` with real Gemini API
- âœ… Updated `controllers/aiController.js` for async operations
- âœ… Fallback mock functions included (if API fails)

---

## ğŸ”‘ Getting Your Gemini API Key

### Step 1: Go to Google AI Studio
Visit: https://aistudio.google.com/app/apikey

### Step 2: Create API Key
1. Click **"Create API Key"** button
2. Select your project or create a new one
3. Copy the generated API key

### Step 3: Add to .env
Open `Backend/.env` and update:
```env
GEMINI_API_KEY=your_actual_api_key_here
GEMINI_MODEL=gemini-flash-latest
```

**Replace** `your_actual_api_key_here` with your real API key.

---

## ğŸ“ Files Modified/Created

| File | Change | Purpose |
|------|--------|---------|
| `Backend/.env` | âœ… Created | Store API keys & config |
| `Backend/utils/aiMock.js` | âœ… Updated | Real Gemini implementation |
| `Backend/controllers/aiController.js` | âœ… Updated | Async support for Gemini |
| `Backend/package.json` | âœ… Updated | Added @google/generative-ai |

---

## ğŸš€ How to Use

### 1. Start Backend
```bash
cd Backend
npm start
```

### 2. Test Report Generation

**cURL:**
```bash
curl -X POST http://localhost:6001/api/generateReport \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "data": {
      "title": "Q1 Performance Report",
      "metrics": {
        "revenue": 500000,
        "users": 5000,
        "growth": "25%"
      },
      "findings": [
        "User base grew by 25%",
        "Revenue exceeded projections",
        "Retention rate improved to 85%"
      ],
      "notes": "Excellent quarter overall"
    },
    "save": true
  }'
```

**Expected Response:**
```json
{
  "generated": {
    "title": "Q1 Performance Report",
    "content": "Professional report generated by Gemini...",
    "metadata": {
      "engine": "gemini-flash-latest",
      "generatedAt": "2026-01-25T...",
      "promptTokens": 150,
      "outputTokens": 450
    }
  },
  "saved": {
    "id": 1,
    "title": "Q1 Performance Report",
    "content": "...",
    "createdAt": "..."
  }
}
```

### 3. Test PDF Chat

**cURL:**
```bash
curl -X POST http://localhost:6001/api/chatWithPdf \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "pdfText": "This document discusses the implementation of machine learning models for financial forecasting. The introduction covers the basics of ML algorithms. The conclusion recommends using ensemble methods for better accuracy.",
    "message": "What does the document recommend?",
    "pdfId": 1
  }'
```

**Expected Response:**
```json
{
  "reply": "According to the document, it recommends using ensemble methods for better accuracy in financial forecasting with machine learning models.",
  "metadata": {
    "engine": "gemini-flash-latest",
    "generatedAt": "2026-01-25T...",
    "promptTokens": 120,
    "outputTokens": 80
  }
}
```

---

## ğŸ”§ Configuration Details

### Environment Variables (.env)

```env
# Server Config
PORT=6001
DB_TYPE=sql
JWT_SECRET=your_secret_key_here
JWT_EXPIRES_IN=7d
CORS_ORIGINS=http://localhost:5501,http://127.0.0.1:5501,http://localhost:3000

# Gemini API Configuration
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-flash-latest
```

### Model Information
- **Model**: `gemini-flash-latest`
- **Type**: Lightweight, fast, cost-effective
- **Use Cases**: Report generation, document analysis, chat
- **Token Limits**: Check Google AI documentation

---

## ğŸ“Š Token Usage Tracking

The response includes token usage information:
```json
{
  "metadata": {
    "promptTokens": 150,      // Tokens sent to API
    "outputTokens": 450       // Tokens in response
  }
}
```

Use this to monitor API costs.

---

## âš ï¸ Error Handling

### Missing API Key
```
Error: GEMINI_API_KEY environment variable is required
```
**Solution:** Add GEMINI_API_KEY to `.env` file

### API Rate Limit
```
Error: 429 Too Many Requests
```
**Solution:** Wait a moment, then retry. Gemini has usage limits.

### Fallback to Mock
If Gemini API fails, the system will gracefully fall back to mock implementations. Check logs for errors.

---

## ğŸ”„ Switching Between Real and Mock

The code supports both:

### Use Real Gemini (Default)
```javascript
const response = await aiMock.chatWithPdf(pdfText, message);
```

### Use Mock (For Testing)
```javascript
const response = aiMock.chatWithPdfMock(pdfText, message);
```

---

## ğŸ“ˆ Performance Tips

1. **Use gemini-flash-latest** - Faster and cheaper than pro models
2. **Batch requests** - Send multiple requests together
3. **Monitor tokens** - Check usage in responses
4. **Cache results** - Store generated reports in DB
5. **Add timeouts** - Prevent hanging requests

---

## ğŸ” Security Best Practices

1. âœ… **Never commit .env file** - Already in .gitignore
2. âœ… **Use environment variables** - Store API key securely
3. âœ… **Validate inputs** - Check data before sending to API
4. âœ… **Limit API calls** - Add rate limiting
5. âœ… **Log errors** - Monitor API issues

---

## ğŸ§ª Testing Checklist

- [ ] Backend starts without errors
- [ ] API key is set in .env
- [ ] `/api/generateReport` endpoint works
- [ ] `/api/chatWithPdf` endpoint works
- [ ] Reports are saved to database
- [ ] Chat messages are stored
- [ ] Token usage is tracked
- [ ] Error messages are helpful

---

## ğŸ“š Useful Resources

- **Google AI Studio**: https://aistudio.google.com
- **Gemini API Docs**: https://ai.google.dev/docs
- **Model Info**: https://ai.google.dev/models/gemini-flash
- **Pricing**: https://ai.google.dev/pricing

---

## âœ¨ Next Steps

1. **Add your API key** to `.env`
2. **Start the backend** with `npm start`
3. **Test the endpoints** using curl or Postman
4. **Monitor token usage** in responses
5. **Optimize prompts** for better results

---

**Your Gemini integration is ready to go! ğŸš€**

Need help? Check the error logs in the terminal for debugging.
